{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "\n",
    "(source_clean_fs, source_clean_data) = wavfile.read('./data/source_clean.wav')\n",
    "(plini_clean_fs, plini_clean_data) = wavfile.read('./data/plini_clean.wav')\n",
    "(source_noise_fs, source_noise_data) = wavfile.read('./data/source_noise.wav')\n",
    "(plini_noise_fs, plini_noise_data) = wavfile.read('./data/plini_noise.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_clean_df = pd.DataFrame(source_clean_data, columns=['L', 'R'])\n",
    "source_clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plini_clean_df = pd.DataFrame(plini_clean_data, columns=['L', 'R'])\n",
    "plini_clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_noise_df = pd.DataFrame(source_noise_data, columns=['L', 'R'])\n",
    "source_noise_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plini_noise_df = pd.DataFrame(plini_noise_data, columns=['L', 'R'])\n",
    "plini_noise_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plini_clean_df['L'].max(), plini_noise_df['L'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 ** 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VALUE = 2 ** 15 - 1\n",
    "MAX_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(plini_clean_df), len(source_clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(plini_noise_df), len(source_noise_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_START_END = int(len(plini_clean_df) * 0.8)\n",
    "CLEAN_START_END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_START_END = int(len(plini_noise_df) * 0.8)\n",
    "NOISE_START_END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_c_start, X_train_c_end) = (0, CLEAN_START_END)\n",
    "(X_test_c_start, X_test_c_end) = (CLEAN_START_END, len(source_clean_df))\n",
    "(y_train_c_start, y_train_c_end) = (0, CLEAN_START_END)\n",
    "(y_test_c_start, y_test_c_end) = (CLEAN_START_END, len(plini_clean_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_n_start, X_train_n_end) = (0, NOISE_START_END)\n",
    "(X_test_n_start, X_test_n_end) = (NOISE_START_END, len(source_noise_df))\n",
    "(y_train_n_start, y_train_n_end) = (0, NOISE_START_END)\n",
    "(y_test_n_start, y_test_n_end) = (NOISE_START_END, len(source_noise_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IT'S MONO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_c_raw = source_clean_df['L'][X_train_c_start:X_train_c_end]\n",
    "X_train_c_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_c_raw = source_clean_df['L'][X_test_c_start:X_test_c_end]\n",
    "X_test_c_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_c_raw = plini_clean_df['L'][y_train_c_start:y_train_c_end]\n",
    "y_train_c_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_c_raw = plini_clean_df['L'][y_test_c_start:y_test_c_end]\n",
    "y_test_c_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_c_raw = source_clean_df['L'][X_train_c_start:X_train_c_end]\n",
    "X_train_c_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_c_raw = source_clean_df['L'][X_test_c_start:X_test_c_end]\n",
    "X_test_c_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_c_raw = plini_clean_df['L'][y_train_c_start:y_train_c_end]\n",
    "y_train_c_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_c_raw = plini_clean_df['L'][y_test_c_start:y_test_c_end]\n",
    "y_test_c_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_n_raw = source_noise_df['L'][X_train_n_start:X_train_n_end]\n",
    "X_train_n_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_n_raw = source_noise_df['L'][X_test_n_start:X_test_n_end]\n",
    "X_test_n_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_n_raw = plini_noise_df['L'][y_train_n_start:y_train_n_end]\n",
    "y_train_n_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_n_raw = plini_noise_df['L'][y_test_n_start:y_test_n_end]\n",
    "y_test_n_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR_C_N_DEV = source_clean_fs\n",
    "TR_C_OFFSET_DEV = source_clean_fs * 2\n",
    "\n",
    "TE_C_N_DEV = int(source_clean_fs / 8)\n",
    "TE_C_OFFSET_DEV = source_clean_fs * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR_N_N_DEV = source_noise_fs\n",
    "TR_N_OFFSET_DEV = source_noise_fs * 2\n",
    "\n",
    "TE_N_N_DEV = int(TE_C_N_DEV / 10)\n",
    "TE_N_OFFSET_DEV = source_noise_fs * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(TR_C_N_DEV, TE_C_N_DEV, TR_N_N_DEV, TE_N_N_DEV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_WINDOW_POINTS = int(source_clean_fs * 0.02)\n",
    "N_WINDOW_POINTS = 64\n",
    "N_WINDOW_POINTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_windows(df, n_window_points):\n",
    "    df_index = df.index\n",
    "    index = 0\n",
    "    windows = []\n",
    "\n",
    "    for index in range(0, len(df) - n_window_points):\n",
    "        windows.append(df_index[index:(index + n_window_points)])\n",
    "\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_c_wnd = make_windows(X_train_c_raw[TR_C_OFFSET_DEV:TR_C_OFFSET_DEV+TR_C_N_DEV], N_WINDOW_POINTS)\n",
    "len(X_train_c_wnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_c_wnd = make_windows(X_test_c_raw[TE_C_OFFSET_DEV:TE_C_OFFSET_DEV+TE_C_N_DEV], N_WINDOW_POINTS)\n",
    "len(X_test_c_wnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_c_wnd = make_windows(y_train_c_raw[TR_C_OFFSET_DEV:TR_C_OFFSET_DEV+TR_C_N_DEV], N_WINDOW_POINTS)\n",
    "len(y_train_c_wnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_c_wnd = make_windows(y_test_c_raw[TE_C_OFFSET_DEV:TE_C_OFFSET_DEV+TE_C_N_DEV], N_WINDOW_POINTS)\n",
    "len(y_test_c_wnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_n_wnd = make_windows(X_train_n_raw[TR_N_OFFSET_DEV:TR_N_OFFSET_DEV+TR_N_N_DEV], N_WINDOW_POINTS)\n",
    "len(X_train_n_wnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_n_wnd = make_windows(X_test_n_raw[TE_N_OFFSET_DEV:TE_N_OFFSET_DEV+TE_N_N_DEV], N_WINDOW_POINTS)\n",
    "len(X_test_n_wnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_n_wnd = make_windows(y_train_n_raw[TR_N_OFFSET_DEV:TR_N_OFFSET_DEV+TR_N_N_DEV], N_WINDOW_POINTS)\n",
    "len(y_train_n_wnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_n_wnd = make_windows(y_test_n_raw[TE_N_OFFSET_DEV:TE_N_OFFSET_DEV+TE_N_N_DEV], N_WINDOW_POINTS)\n",
    "len(y_test_n_wnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_c_wnd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test_c_raw[X_test_c_wnd[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = (\n",
    "    list(map(lambda wnd: X_train_c_raw[wnd], X_train_c_wnd)) +\n",
    "    list(map(lambda wnd: X_train_n_raw[wnd], X_train_n_wnd))\n",
    ")\n",
    "\n",
    "X_train[0], X_train[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test = (\n",
    "    list(map(lambda wnd: X_test_c_raw[wnd], X_test_c_wnd)) +\n",
    "    list(map(lambda wnd: X_test_n_raw[wnd], X_test_n_wnd))\n",
    ")\n",
    "\n",
    "X_test[0], X_test[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = (\n",
    "    list(map(lambda wnd: y_train_c_raw[wnd], y_train_c_wnd)) +\n",
    "    list(map(lambda wnd: y_train_n_raw[wnd], y_train_n_wnd))\n",
    ")\n",
    "\n",
    "y_train[0], y_train[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test = (\n",
    "    list(map(lambda wnd: y_test_c_raw[wnd], y_test_c_wnd)) +\n",
    "    list(map(lambda wnd: y_test_n_raw[wnd], y_test_n_wnd))\n",
    ")\n",
    "\n",
    "y_test[0], y_test[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_shuffle_index = np.arange(0, len(X_train))\n",
    "np.random.shuffle(train_shuffle_index)\n",
    "\n",
    "test_shuffle_index = np.arange(0, len(X_test))\n",
    "np.random.shuffle(test_shuffle_index)\n",
    "\n",
    "X_train = np.array(X_train)[train_shuffle_index]\n",
    "y_train = np.array(y_train)[train_shuffle_index]\n",
    "\n",
    "X_test = np.array(X_test)[test_shuffle_index]\n",
    "y_test = np.array(y_test)[test_shuffle_index]\n",
    "\n",
    "X_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_keeping_mean(arr, forced_abs=None):\n",
    "    left_abs = np.abs(arr.mean() - arr.min())\n",
    "    right_abs = np.abs(arr.max() - arr.mean())\n",
    "    \n",
    "    n = max(left_abs, right_abs)\n",
    "    \n",
    "    if (forced_abs is not None):\n",
    "        n = forced_abs\n",
    "    \n",
    "    return np.clip(arr / n, -1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(arr, forced_abs=None, mean=None):\n",
    "    left_abs = np.abs(arr.mean() - arr.min())\n",
    "    right_abs = np.abs(arr.max() - arr.mean())\n",
    "    \n",
    "    n = max(left_abs, right_abs)\n",
    "    \n",
    "    if (forced_abs is not None):\n",
    "        n = forced_abs\n",
    "        \n",
    "    if (mean is None):\n",
    "        mean = arr.mean()\n",
    "    \n",
    "    \n",
    "    return np.clip((arr - mean) / n, -1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_tr = np.array(list(map(lambda x: np.array(x), X_train)))\n",
    "X_tr_n = normalize(X_tr, forced_abs=MAX_VALUE, mean=0.0)\n",
    "X_tr_n.min(), X_tr_n.max(), np.mean(X_tr_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te = np.array(list(map(lambda x: np.array(x), X_test)))\n",
    "X_te_n = normalize_keeping_mean(X_te, forced_abs=MAX_VALUE)\n",
    "X_te_n.min(), X_te_n.max(), np.mean(X_te_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = np.array(list(map(lambda x: np.array(x), y_train)))\n",
    "y_tr_n = normalize_keeping_mean(y_tr, forced_abs=MAX_VALUE)\n",
    "y_tr_n.min(), y_tr_n.max(), np.mean(y_tr_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_te = np.array(list(map(lambda x: np.array(x), y_test)))\n",
    "y_te_n = normalize_keeping_mean(y_te, forced_abs=MAX_VALUE)\n",
    "y_te_n.min(), y_te_n.max(), np.mean(y_te_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_n = X_tr_n.astype('float32')\n",
    "X_te_n = X_te_n.astype('float32')\n",
    "y_tr_n = y_tr_n.astype('float32')\n",
    "y_te_n = y_te_n.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.Series(X_tr_n[-100]).plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_tr_n[-100]).plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(X_te_n[-100]).plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_te_n[-100]).plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to apply FFT to data\n",
    "\n",
    "The plan is to apply FFT, and take the freqs and amplitudes of first N peaks, feeding it into NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wnd = X_te[1]\n",
    "test_wnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FD = 22050 * 2\n",
    "FD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(test_wnd).plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.fft import rfft, fftfreq, rfftfreq\n",
    "\n",
    "freq = rfftfreq(32, 1./FD)\n",
    "max_freq = freq[-1]\n",
    "\n",
    "print(max_freq)\n",
    "\n",
    "fft = rfft(test_wnd)\n",
    "\n",
    "df = pd.Series(fft)\n",
    "\n",
    "index = []\n",
    "\n",
    "for i in range(0, len(fft)):\n",
    "    index = index + [(i / len(fft)) * max_freq]\n",
    "\n",
    "print(index)\n",
    "\n",
    "df.index = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.map(lambda x: x.imag).plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "(fig, ax) = plt.subplots(figsize=(16, 8))\n",
    "df.plot.line(ax=ax)\n",
    "\n",
    "peaks_re = find_peaks(df.map(lambda x: x.real))[0]\n",
    "peaks_im = find_peaks(df.map(lambda x: x.imag))[0]\n",
    "\n",
    "pd.DataFrame(df.iloc[peaks_re]).plot.line(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_peaks(df, peaks, N):\n",
    "    res = df.iloc[peaks[:N]]\n",
    "\n",
    "    for i in range(len(peaks), N_PEAKS):\n",
    "        res = res.append(pd.Series([0], index=[0]))\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PEAKS = 10\n",
    "\n",
    "peaks_re = append_peaks(df, peaks_re, N_PEAKS)\n",
    "peaks_im = append_peaks(df, peaks_im, N_PEAKS)\n",
    "\n",
    "(peaks_re, peaks_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.fft import rfft, fftfreq, rfftfreq\n",
    "from scipy.signal import find_peaks\n",
    "from matplotlib import pyplot as plt\n",
    "import librosa as lr\n",
    "\n",
    "MAGIC_NUMBER = 22050\n",
    "MAGIC_CENTROID_NUMBER = 10000\n",
    "MAGIC_ROLLOFF_NUMBER = 20000\n",
    "\n",
    "def extract_fft_features(wnd, N_PEAKS):\n",
    "    # Apply FFT\n",
    "    \n",
    "    freq = rfftfreq(N_WINDOW_POINTS, 1./FD)\n",
    "    max_freq = FD / 2\n",
    "    \n",
    "\n",
    "    fft = rfft(wnd)\n",
    "\n",
    "    df = pd.Series(fft)\n",
    "\n",
    "    index = []\n",
    "\n",
    "    for i in range(0, len(fft)):\n",
    "        index = index + [(i / (len(fft) - 1))]\n",
    "\n",
    "    df.index = index\n",
    "\n",
    "    # Output FFT\n",
    "    \n",
    "    real = normalize(\n",
    "         np.array(list(map(lambda x: x.real, df.values))),\n",
    "         forced_abs=MAGIC_NUMBER,\n",
    "         mean=0.0\n",
    "    )\n",
    "    \n",
    "    imag = normalize(\n",
    "        np.array(list(map(lambda x: x.imag, df.values))),\n",
    "        forced_abs=MAGIC_NUMBER,\n",
    "        mean=0.0\n",
    "    )\n",
    "    \n",
    "\n",
    "    res = {'df': df, 'data': np.concatenate([real, imag])}\n",
    "    \n",
    "    return res\n",
    "    \n",
    "    \n",
    "\n",
    "def extract_spectral_features(wnd, fft_df, N_PEAKS):    \n",
    "    real = np.array(list(map(lambda x: x.real, fft_df.values)))\n",
    "    imag = np.array(list(map(lambda x: x.imag, fft_df.values)))\n",
    "    \n",
    "\n",
    "    # Output spectral\n",
    "    \n",
    "    real_stats = [\n",
    "        real.mean(),\n",
    "        real.std(),\n",
    "        real.max(),\n",
    "        real.min(),\n",
    "    ]   \n",
    "    \n",
    "    imag_stats = [\n",
    "        imag.mean(),\n",
    "        imag.std(),\n",
    "        imag.max(),\n",
    "        imag.min(),\n",
    "    ]\n",
    "    \n",
    "#     print(lr.onset.onset_detect(wnd.astype('float64')))\n",
    "    \n",
    "    stats = [\n",
    "        lr.feature.spectral_centroid(wnd.astype('float64'))[0][0] / MAGIC_CENTROID_NUMBER,\n",
    "        lr.feature.spectral_rolloff(wnd.astype('float64'))[0][0] / MAGIC_ROLLOFF_NUMBER\n",
    "    ]\n",
    "\n",
    "    \n",
    "    # Find peaks\n",
    "\n",
    "#     peaks_re = find_peaks(real)[0]\n",
    "#     peaks_im = find_peaks(imag)[0]\n",
    "\n",
    "#     peaks_re = append_peaks(fft_df, peaks_re, N_PEAKS)\n",
    "#     peaks_im = append_peaks(fft_df, peaks_im, N_PEAKS)\n",
    "    \n",
    "#     print(peaks_re)\n",
    "    \n",
    "#     features_re = (\n",
    "#          list(np.array(list(peaks_re.index))) +\n",
    "#          list(normalize(np.array(list(map(lambda x: x.real, peaks_re.get_values()))), forced_abs=MAGIC_NUMBER, mean=0.0))\n",
    "#     )\n",
    "    \n",
    "#     features_im = (\n",
    "#          list(np.array(list(peaks_im.index))) +\n",
    "#          list(normalize(np.array(list(map(lambda x: x.imag, peaks_im.get_values()))), forced_abs=MAGIC_NUMBER, mean=0.0))\n",
    "#     )\n",
    "\n",
    "#     res = np.concatenate([real_stats, imag_stats, features_re, features_im, stats])\n",
    "    res = np.concatenate([real_stats, imag_stats, stats])\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_res = extract_fft_features(test_wnd, N_PEAKS)\n",
    "extract_spectral_features(fft_res['data'], fft_res['df'], N_PEAKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it. fucking. works.\n",
    "# Hail God."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_features_X(X):\n",
    "    res = []\n",
    "    \n",
    "    for wnd in X:\n",
    "        # res.append(np.array(list(wnd) + list(extract_fft_features(wnd, N_PEAKS))))\n",
    "        fft = extract_fft_features(wnd, N_PEAKS)\n",
    "        \n",
    "        res.append(np.concatenate([\n",
    "            fft['data'],\n",
    "            extract_spectral_features(fft['data'], fft['df'], N_PEAKS)\n",
    "        ]))\n",
    "    \n",
    "    return np.array(res)\n",
    "\n",
    "def append_features_y(X):\n",
    "    res = []\n",
    "    \n",
    "    for wnd in X:\n",
    "        # res.append(np.array(list(wnd) + list(extract_fft_features(wnd, N_PEAKS))))\n",
    "        fft = extract_fft_features(wnd, N_PEAKS)\n",
    "        res.append(fft['data'])\n",
    "    \n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_features_X(X_tr_n[:1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(X_tr), len(X_te), len(y_tr), len(y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# N_DEV_2 = 10000\n",
    "\n",
    "X_tr_f = append_features_X(X_tr_n)\n",
    "print('X_tr_f finished...')\n",
    "\n",
    "X_te_f = append_features_X(X_te_n)\n",
    "print('X_te_f finished...')\n",
    "\n",
    "y_tr_f = append_features_y(y_tr_n)\n",
    "print('y_tr_f finished...')\n",
    "\n",
    "y_te_f = append_features_y(y_te_n)\n",
    "print('y_te_f finished...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(X_tr_f[100]).plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_tr_f[100]).plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(X_te_f[100]).plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_te_f[100]).plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_te_f[0], y_te_f[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.max(list(map(lambda row: row[65:], X_te_f)))\n",
    "np.max(list(map(lambda row: row, X_te_f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending stats of the whole sample, fading from silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_shuffle_index = np.random.shuffle(np.arange(0, len(X_tr_f)))\n",
    "test_shuffle_index = np.random.shuffle(np.arange(0, len(X_te_f)))\n",
    "\n",
    "X_tr_f = X_tr_f[train_shuffle_index][0]\n",
    "y_tr_f = y_tr_f[train_shuffle_index][0]\n",
    "\n",
    "X_te_f = X_te_f[test_shuffle_index][0]\n",
    "y_te_f = y_te_f[test_shuffle_index][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(X_tr_f[0]), len(y_tr_f[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURES_X = 76\n",
    "N_FEATURES_y = 66\n",
    "\n",
    "N_FEATURES_X, N_FEATURES_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(lambda row: row[N_PEAKS:N_PEAKS*2], X_tr_f))[0]\n",
    "# list(map(lambda row: row[:N_PEAKS], X_tr_f))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amp_df = pd.DataFrame(list(map(lambda row: row[N_PEAKS:N_PEAKS*2], X_tr_f)))\n",
    "amp_df = pd.DataFrame(list(map(lambda row: row, X_tr_f)))\n",
    "\n",
    "f = plt.figure(figsize=(19, 15))\n",
    "plt.matshow(amp_df.corr())\n",
    "plt.xticks(range(amp_df.shape[1]), amp_df.columns, fontsize=14, rotation=45)\n",
    "plt.yticks(range(amp_df.shape[1]), amp_df.columns, fontsize=14)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=14)\n",
    "plt.title('Correlation Matrix', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finished data processing!\n",
    "\n",
    "## Moving on to training NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_f.shape, X_tr_f.shape, X_te_f.shape, y_te_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_f[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(79, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(171, activation='relu'))\n",
    "model.add(Dense(327, activation='relu'))\n",
    "model.add(Dense(171, activation='relu'))\n",
    "model.add(Dense(65, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(N_FEATURES_y, activation=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Dense(49, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(87, activation='relu'))\n",
    "# model.add(Dense(49, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(N_FEATURES, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(X_tr_f, y_tr_f, batch_size=32, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_te_f, y_te_f, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.7349040782270075e-09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te_f[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, row):\n",
    "    return model.predict(np.array([row]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(model, X_te_f[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "\n",
    "(fig, ax) = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "I = 200\n",
    "\n",
    "pd.Series(y_te_f[I]).plot.line(ax=ax, label='intended')\n",
    "\n",
    "pred = pd.Series(predict(model, X_te_f[I]))\n",
    "\n",
    "pred.plot.line(ax=ax, label='predicted')\n",
    "\n",
    "# pd.Series(savgol_filter(pred, 5, 3)).plot.line(ax=ax, label='savgol(predicted)')\n",
    "\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set_xlabel('index')\n",
    "ax.set_ylabel('value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Til next time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_peaks(peaks, N):\n",
    "    df = pd.Series()\n",
    "    \n",
    "    for i in range(0, N):\n",
    "        df = df.append(pd.Series([peaks[N + i]], index=[peaks[i]]))\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.fft import rfft, fftfreq, rfftfreq\n",
    "from scipy.signal import find_peaks\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "MAGIC_NUMBER = 22050\n",
    "\n",
    "def unpack_fft_features(row, N_PEAKS):  \n",
    "    # Unpack peaks\n",
    "    \n",
    "    features_re = row[:2*N_PEAKS]\n",
    "    features_im = row[2*N_PEAKS:]\n",
    "    \n",
    "    df = pd.Series()\n",
    "    \n",
    "    peaks_re = unpack_peaks(features_re, N_PEAKS)\n",
    "    peaks_im = unpack_peaks(features_im, N_PEAKS)\n",
    "    \n",
    "    peaks = (peaks_re * complex(1, 0)).add(peaks_im * complex(0, 1))\n",
    "    \n",
    "    print(peaks)\n",
    "    \n",
    "    return []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Apply IFFT\n",
    "    \n",
    "    freq = rfftfreq(N_WINDOW_POINTS, 1./FD)\n",
    "    max_freq = freq[-1]\n",
    "\n",
    "    fft = rfft(wnd)\n",
    "\n",
    "    df = pd.Series(fft)\n",
    "\n",
    "    index = []\n",
    "\n",
    "    for i in range(0, len(fft)):\n",
    "        index = index + [(i / len(fft))]\n",
    "\n",
    "    df.index = index\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "I = 200\n",
    "\n",
    "unpack_fft_features(predict(model, X_te_f[I]), N_PEAKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
